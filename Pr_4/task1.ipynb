{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj3MozQen0ND"
      },
      "source": [
        "## Lab 4. Advanced nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TCfOx45n0NE"
      },
      "source": [
        "1.  Завдання щодо генерації текстів або машинного перекладу (на вибір) на базі рекурентних мереж або трансформерів (на вибір).\n",
        "Вирішіть завдання щодо генерації текстів або машинного перекладу. Особливо вітаються україномовні моделі.  \n",
        "\n",
        "Датасети для перекладу можна брати тут: https://www.manythings.org/anki/\n",
        "Тексти українською для навчання генеративних моделей: https://www.kaggle.com/datasets/mykras/ukrainian-texts\n",
        "Приклади:\n",
        "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/\n",
        "https://keras.io/examples/nlp/lstm_seq2seq/\n",
        "https://keras.io/examples/generative/lstm_character_level_text_generation/\n",
        "\n",
        "Для виконання роботи я обрав рекурентну мережу для задачі генерації тексту на основі декількох історичних книг українською мовою"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "n1fA_014yasu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of input files\n",
        "# I chose several ukrainian historical books from https://javalibre.com.ua/java-book/\n",
        "input_files = ['text_1.txt', 'text_2.txt', 'text_3.txt', 'text_4.txt']\n",
        "\n",
        "# Define the output file\n",
        "output_file = 'ukr_text.txt'\n",
        "\n",
        "def combine_text_files(input_files, output_file):\n",
        "    \"\"\"\n",
        "    Combines multiple text files into a single output file.\n",
        "\n",
        "    Args:\n",
        "        input_files (list): List of input file paths.\n",
        "        output_file (str): Path to the output combined file.\n",
        "    \"\"\"\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        for fname in input_files:\n",
        "            if os.path.exists(fname):\n",
        "                with open(fname, 'r', encoding='utf-8') as infile:\n",
        "                    content = infile.read()\n",
        "                    outfile.write(content)\n",
        "                    outfile.write('\\n\\n')  # Add double newline between files for separation\n",
        "                print(f\"Successfully added {fname}\")\n",
        "            else:\n",
        "                print(f\"Warning: File {fname} does not exist and was skipped.\")\n",
        "\n",
        "# Combine the text files\n",
        "combine_text_files(input_files, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8siOwsTZyfF-",
        "outputId": "a952fe94-7a52-477d-97e4-cc9767d19a93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added text_1.txt\n",
            "Successfully added text_2.txt\n",
            "Successfully added text_3.txt\n",
            "Successfully added text_4.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the Combined Text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocesses the input text by converting to lowercase and removing unwanted characters.\n",
        "\n",
        "    Args:\n",
        "        text (str): Raw input text.\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned and preprocessed text.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    # Define allowed characters (Ukrainian alphabets, space, and basic punctuation)\n",
        "    allowed_chars = 'абвгґдеєжзиіїйклмнопрстуфхцчшщьюя ,.!?\\n'\n",
        "    text = ''.join(c for c in text if c in allowed_chars)\n",
        "    return text\n",
        "\n",
        "# Read the combined text from 'ukr_text.txt'\n",
        "with open('ukr_text.txt', 'r', encoding='utf-8') as f:\n",
        "    sample_text = f.read()\n",
        "\n",
        "# Preprocess the text\n",
        "text = preprocess_text(sample_text)\n",
        "print(f\"Total Characters after Preprocessing: {len(text)}\")\n",
        "\n",
        "# Create Character Mappings\n",
        "\n",
        "# Create a sorted list of unique characters\n",
        "chars = sorted(list(set(text)))\n",
        "print(f\"Unique Characters: {len(chars)}\")\n",
        "print(f\"Characters: {chars}\")\n",
        "\n",
        "# Create mapping from characters to indices\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# Create Input Sequences and Targets\n",
        "\n",
        "# Define sequence length and step size\n",
        "seq_length = 40  # Length of each input sequence\n",
        "step = 3         # Step size for moving the window\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - seq_length, step):\n",
        "    sentences.append(text[i: i + seq_length])\n",
        "    next_chars.append(text[i + seq_length])\n",
        "\n",
        "print(f\"Number of sequences: {len(sentences)}\")\n",
        "\n",
        "# Vectorization\n",
        "\n",
        "# Initialize input and output arrays\n",
        "X = np.zeros((len(sentences), seq_length), dtype=np.int32)\n",
        "y = np.zeros((len(sentences), vocab_size), dtype=np.float32)  # Ensure dtype is float32\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    X[i] = [char_to_idx[c] for c in sentence]\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1.0  # Use float32 for compatibility\n",
        "\n",
        "print(\"Vectorization Complete.\")\n",
        "\n",
        "# Build the LSTM-Based RNN Model\n",
        "\n",
        "# Define model parameters\n",
        "embedding_dim = 100\n",
        "lstm_units = 256\n",
        "dropout_rate = 0.2\n",
        "batch_size = 128\n",
        "epochs = 20  # Adjust as needed\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length))\n",
        "model.add(LSTM(lstm_units, return_sequences=True))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(LSTM(lstm_units))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "kBukYirryhH8",
        "outputId": "cde39476-02fb-4fcf-db6f-b9f1d860625f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters after Preprocessing: 793855\n",
            "Unique Characters: 39\n",
            "Characters: ['\\n', ' ', '!', ',', '.', '?', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ь', 'ю', 'я', 'є', 'і', 'ї', 'ґ']\n",
            "Number of sequences: 264605\n",
            "Vectorization Complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "\n",
        "# Define EarlyStopping callback to prevent overfitting\n",
        "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X, y,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoGYrsvfykuy",
        "outputId": "25fc89f3-d393-4f27-ab1a-44f5e2bfd29b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - loss: 2.6789\n",
            "Epoch 2/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - loss: 1.8901\n",
            "Epoch 3/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.6904\n",
            "Epoch 4/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.5925\n",
            "Epoch 5/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.5303\n",
            "Epoch 6/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - loss: 1.4876\n",
            "Epoch 7/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - loss: 1.4461\n",
            "Epoch 8/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.4168\n",
            "Epoch 9/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.3934\n",
            "Epoch 10/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.3677\n",
            "Epoch 11/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - loss: 1.3522\n",
            "Epoch 12/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.3305\n",
            "Epoch 13/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.3164\n",
            "Epoch 14/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.3003\n",
            "Epoch 15/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - loss: 1.2876\n",
            "Epoch 16/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - loss: 1.2783\n",
            "Epoch 17/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 16ms/step - loss: 1.2688\n",
            "Epoch 18/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - loss: 1.2570\n",
            "Epoch 19/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - loss: 1.2522\n",
            "Epoch 20/20\n",
            "\u001b[1m2068/2068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 16ms/step - loss: 1.2447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Generation Function\n",
        "\n",
        "def generate_text(model, seed, length=200, temperature=0.8):\n",
        "    \"\"\"\n",
        "    Generates text using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (keras.Model): Trained Keras model.\n",
        "        seed (str): Seed text to start generation.\n",
        "        length (int): Number of characters to generate.\n",
        "        temperature (float): Controls randomness in prediction.\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text.\n",
        "    \"\"\"\n",
        "    generated = seed\n",
        "    for _ in range(length):\n",
        "        # Preprocess the current generated text\n",
        "        seed_processed = preprocess_text(generated)\n",
        "        seed_processed = seed_processed[-seq_length:]\n",
        "\n",
        "        # Pad seed if it's shorter than seq_length\n",
        "        if len(seed_processed) < seq_length:\n",
        "            seed_processed = ' ' * (seq_length - len(seed_processed)) + seed_processed\n",
        "\n",
        "        # Convert characters to indices\n",
        "        input_seq = np.array([char_to_idx.get(c, 0) for c in seed_processed]).reshape(1, seq_length)\n",
        "\n",
        "        # Predict the next character probabilities\n",
        "        preds = model.predict(input_seq, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Sample the next character index using np.random.choice\n",
        "        next_index = np.random.choice(range(vocab_size), p=preds)\n",
        "        next_char = idx_to_char[next_index]\n",
        "\n",
        "        # Append the next character to the generated text\n",
        "        generated += next_char\n",
        "\n",
        "    return generated\n"
      ],
      "metadata": {
        "id": "evaCvoyPymFP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and Display Sample Text\n",
        "\n",
        "# Define a seed prompt in Ukrainian\n",
        "seed_prompt = \"Україна перемогла\"\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(model, seed_prompt, length=50, temperature=0.8)\n",
        "\n",
        "# Display the generated text\n",
        "print(\"Generated Text:\\n\")\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh3ZEmHpynPO",
        "outputId": "ff8e2c09-6abb-4cb4-c8b3-97ac61c81e40"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "\n",
            "Україна перемогла без партії. в листопаді  не почали собі відмовивс\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a file\n",
        "model.save('ukrainian_text_generator_final.h5')\n"
      ],
      "metadata": {
        "id": "PHVi2yFT3H-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used google colab T4 GPU to train the model. Since provided text wasn't as big, number of epocs only 20 (to train the model faster) I get not the best responses from he model"
      ],
      "metadata": {
        "id": "nMwGTpHR4pN9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bN8fuoE2ybF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgbWxTKEybNv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}